MULTILABEL EXPERIMENT REPORT
Generated Mon Jul 10 20:36:14 2023

Args:  -b 26 --learning_rate 1.5 --passes 30 --csoaa 35 --kill_cache --cache_file a.cache

EXPERIMENT WITH 164 TEST CHANGESETS
F1 SCORE : 0.500 weighted, 0.570 micro-avg'd, 0.640 macro-avg'd
PRECISION: 0.767 weighted, 0.756 micro-avg'd, 0.645 macro-avg'd
RECALL   : 0.458 weighted, 0.458 micro-avg'd, 0.752 macro-avg'd

 -----------------CLASSIFICATION REPORT-----------------
                          precision    recall  f1-score   support

              SQLAlchemy       0.67      1.00      0.80         2
                  Scrapy       0.67      1.00      0.80         2
                  Theano       0.67      1.00      0.80         2
                 astropy       0.67      1.00      0.80         2
          beautifulsoup4       0.67      1.00      0.80         2
               biopython       0.67      1.00      0.80         2
                   bokeh       0.67      1.00      0.80         2
                   boto3       0.80      0.13      0.23        30
                   cmake       1.00      0.42      0.59        31
                    dask       0.67      1.00      0.80         2
                    deap       0.67      1.00      0.80         2
                  jinja2       0.83      0.24      0.37        21
              matplotlib       0.80      0.13      0.23        30
                networkx       0.00      0.00      0.00         0
                 nilearn       0.67      1.00      0.80         2
  nvidia-cuda-nvrtc-cu11       0.50      0.10      0.16        21
nvidia-cuda-runtime-cu11       0.67      1.00      0.80         2
           opencv-python       0.67      1.00      0.80         2
                  pandas       0.96      0.92      0.94        26
                  pillow       0.50      0.20      0.29         5
                  plotly       0.67      1.00      0.80         2
                 pycaret       0.67      1.00      0.80         2
                 pyspark       0.67      1.00      0.80         2
                   redis       0.67      1.00      0.80         2
                requests       0.67      1.00      0.80         2
            scikit-image       0.00      0.00      0.00         0
            scikit-learn       0.67      1.00      0.80         2
                   scipy       0.95      0.82      0.88        22
                   scoop       0.67      1.00      0.80         2
              simplejson       0.67      1.00      0.80         2
                     six       0.67      1.00      0.80         2
             statsmodels       0.67      1.00      0.80         2
                  triton       0.33      0.10      0.15        20
           triton==2.0.0       0.40      1.00      0.57         2
                   wheel       0.83      0.26      0.40        19

               micro avg       0.76      0.46      0.57       271
               macro avg       0.64      0.75      0.64       271
            weighted avg       0.77      0.46      0.50       271
             samples avg       0.72      0.59      0.62       271

