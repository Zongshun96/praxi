MULTILABEL EXPERIMENT REPORT
Generated Mon Jul 10 20:36:15 2023

Args:  -b 26 --learning_rate 1.5 --passes 30 --csoaa 35 --kill_cache --cache_file a.cache

EXPERIMENT WITH 164 TEST CHANGESETS
F1 SCORE : 0.254 weighted, 0.111 micro-avg'd, 0.099 macro-avg'd
PRECISION: 0.151 weighted, 0.059 micro-avg'd, 0.057 macro-avg'd
RECALL   : 0.978 weighted, 0.978 micro-avg'd, 0.936 macro-avg'd

 -----------------CLASSIFICATION REPORT-----------------
                          precision    recall  f1-score   support

              SQLAlchemy       0.02      1.00      0.03         2
                  Scrapy       0.02      1.00      0.03         2
                  Theano       0.02      1.00      0.03         2
                 astropy       0.02      1.00      0.03         2
          beautifulsoup4       0.02      1.00      0.03         2
               biopython       0.02      1.00      0.03         2
                   bokeh       0.02      1.00      0.03         2
                   boto3       0.21      0.93      0.34        30
                   cmake       0.22      0.94      0.36        31
                    dask       0.02      1.00      0.03         2
                    deap       0.02      1.00      0.03         2
                  jinja2       0.17      1.00      0.29        21
              matplotlib       0.22      1.00      0.36        30
                networkx       0.00      0.00      0.00         0
                 nilearn       0.02      1.00      0.03         2
  nvidia-cuda-nvrtc-cu11       0.17      1.00      0.29        21
nvidia-cuda-runtime-cu11       0.02      1.00      0.03         2
           opencv-python       0.02      1.00      0.03         2
                  pandas       0.17      1.00      0.29        26
                  pillow       0.04      1.00      0.08         5
                  plotly       0.02      1.00      0.03         2
                 pycaret       0.02      1.00      0.03         2
                 pyspark       0.02      1.00      0.03         2
                   redis       0.02      1.00      0.03         2
                requests       0.02      1.00      0.03         2
            scikit-image       0.00      0.00      0.00         0
            scikit-learn       0.02      1.00      0.03         2
                   scipy       0.14      1.00      0.25        22
                   scoop       0.02      1.00      0.03         2
              simplejson       0.02      1.00      0.03         2
                     six       0.02      1.00      0.03         2
             statsmodels       0.02      1.00      0.03         2
                  triton       0.14      0.90      0.24        20
           triton==2.0.0       0.02      1.00      0.03         2
                   wheel       0.15      1.00      0.26        19

               micro avg       0.06      0.98      0.11       271
               macro avg       0.06      0.94      0.10       271
            weighted avg       0.15      0.98      0.25       271
             samples avg       0.18      0.99      0.23       271

